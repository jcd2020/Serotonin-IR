{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "def open_unicode_file(name):\n",
    "    f =  codecs.open(name, encoding='utf-8', mode='r').read()\n",
    "    return f.split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named spacy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-379dcd385d78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstanford\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStanfordDependencyParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath_to_jar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stanford-parser-full-2018-10-17/stanford-parser.jar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named spacy"
     ]
    }
   ],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "path_to_jar = 'stanford-parser-full-2018-10-17/stanford-parser.jar'\n",
    "path_to_models_jar = 'stanford-parser-full-2018-10-17/stanford-english-corenlp-2018-02-27-models.jar'\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "dependency_parser = StanfordDependencyParser(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)\n",
    "nltk.internals.config_java(options='-Xmx32g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"antagonists.txt\", \"w\")\n",
    "f2 = open(\"agonists.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_antagonists_and_agonists(f1, f2, doc):\n",
    "    count = 0\n",
    "    for text in doc:\n",
    "        nlp_doc = nlp(doc)\n",
    "        for sent in doc.sents:\n",
    "            if count % 10 == 0:\n",
    "                print(count)\n",
    "            if len(sent) == 0:\n",
    "                continue\n",
    "            try:\n",
    "                result = list(dependency_parser.raw_parse(sent))\n",
    "                for l in result:\n",
    "                    s = list(l.triples())\n",
    "                    for dep in s:\n",
    "                        w1 = dep[0][0]\n",
    "                        w2 = dep[2][0]\n",
    "                        if w1 == \"antagonist\":\n",
    "                            f1.write(w2 + \"\\n\")\n",
    "                        if w2 == \"antagonist\":\n",
    "                            f1.write(w1  + \"\\n\")\n",
    "                        if w1 == \"agonist\":\n",
    "                            f2.write(w2 + \"\\n\")\n",
    "                        if w2 == \"agonist\":\n",
    "                            f2.write(w1  + \"\\n\")   \n",
    "                        f1.flush()\n",
    "                        f2.flush()\n",
    "                count += 1\n",
    "            except StopIteration:\n",
    "                print(\"StopIteration: \" + sent)\n",
    "                continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = open_unicode_file(\"../data/5-HT_EndNote_Text_Apr2019.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "StopIteration: \t\n",
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "Parsing file: /tmp/tmp2g1hsJ\n",
      "Parsing [sent. 1 len. 570]: PURPOSE : A prospective observational multicenter trial was carried out to assess the incidence , pattern , and prognostic factors of radiation-induced emesis -LRB- RIE -RRB- , and evaluate the use of antiemetic drugs in radiation oncology clinical practice . METHODS AND MATERIALS : Fifty-one Italian radiation oncology centers took part in this trial . The accrual lasted 2 consecutive weeks , only patients starting radiotherapy in this period were enrolled . Exclusion criteria were age under 18 years , and concomitant chemotherapy . Evaluation was based on diary cards filled in daily by patients during radiotherapy and 1 week after stopping it . Diary cards recorded the intensity of nausea and any episode of vomiting and retching . Prophylactic and symptomatic antiemetic drug prescriptions were also registered . RESULTS : Nine hundred thirty-four patients entered the trial , and 914 were evaluable . Irradiated sites were : breast in 211 patients , pelvis in 210 patients , head and neck in 136 patients , thorax in 129 patients , brain in 52 patients , upper abdomen in 42 patients , skin and/or extremities in 37 patients , and other sites in 97 patients . Vomiting and nausea occurred in 17.1 % and 37.3 % of patients , respectively , and 38.7 % patients had both vomiting and nausea . At multifactorial analysis , the only patient-related risk factor that was statistically significant was represented by previous experience with cancer chemotherapy . Moreover , two radiotherapy -LRB- RT -RRB- - related factors were significant risk factors for RIE , the irradiated site and field size . In fact , a statistically significant higher percentage of RIE was registered in upper abdomen RT and RT fields > 400 cm2 . Although nonstatistically significant , patients receiving RT to the thorax and head and neck presented a higher incidence of RIE . Only a minority -LRB- 14 % -RRB- of patients receiving RT were given an antiemetic drug , and the prescriptions were more often symptomatic than prophylactic -LRB- 9 % vs. 5 % , respectively -RRB- . Different compounds and a wide range of doses and schedules were used ; however , there is some evidence from our data that in spite of antiemetic prophylaxis , 46 % of patients had vomiting , and 58 % had nausea . The majority -LRB- 93 % -RRB- of the prophylactic group received oral 5-hydroxytriptamine receptor -LRB- 5-HT3 -RRB- antagonist -LRB- 8 mg/day , 7 days/week -RRB- . In the symptomatic group , 54 % and 41 % patients received 5-HT3 antagonists and metoclopramide , respectively . At multivariate analysis , no patient - or RT-related risk factor for RIE was found to influence significantly the prophylactic or symptomatic use of antiemetics . CONCLUSION : Our study provided useful data on epidemiology and characteristics of RIE . Previous chemotherapy , field size , and irradiated site -LRB- upper abdomen -RRB- were the only significant prognostic factors of RIE . A remarkable incidence of RIE was found in patients submitted to thoracic and head and neck RT. . With this background of knowledge , it will be possible to better plan further studies on this important problem . Moreover , the low rate of antiemetics use and the wide variety of doses and schedules employed suggest the need to reinforce the `` evidence based '' approach to identify the best antiemetic approach to RIE .\n",
      "Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n",
      "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.parseAndReport(LexicalizedParserQuery.java:706)\n",
      "\tat edu.stanford.nlp.parser.lexparser.ParseFiles.parseFiles(ParseFiles.java:215)\n",
      "\tat edu.stanford.nlp.parser.lexparser.ParseFiles.parseFiles(ParseFiles.java:75)\n",
      "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(LexicalizedParser.java:1518)\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Java command failed : [u'/usr/bin/java', u'-mx4g', '-cp', 'stanford-parser-full-2018-10-17/stanford-english-corenlp-2018-02-27-models.jar:stanford-parser-full-2018-10-17/stanford-english-corenlp-2018-02-27-models.jar:stanford-parser-full-2018-10-17/stanford-parser-3.9.2-sources.jar:stanford-parser-full-2018-10-17/stanford-parser-3.9.2-models.jar:stanford-parser-full-2018-10-17/slf4j-api-1.7.12-sources.jar:stanford-parser-full-2018-10-17/stanford-parser.jar:stanford-parser-full-2018-10-17/slf4j-api.jar:stanford-parser-full-2018-10-17/ejml-0.23.jar:stanford-parser-full-2018-10-17/stanford-parser-3.9.2-javadoc.jar', u'edu.stanford.nlp.parser.lexparser.LexicalizedParser', u'-model', u'edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz', u'-sentences', u'newline', u'-outputFormat', u'conll2007', u'-encoding', u'utf8', '/tmp/tmp2g1hsJ']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-72b6179e6838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_antagonists_and_agonists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-29f2799d27d8>\u001b[0m in \u001b[0;36mprint_antagonists_and_agonists\u001b[0;34m(f1, f2, doc)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependency_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jeremydohmann/.local/lib/python2.7/site-packages/nltk/parse/stanford.pyc\u001b[0m in \u001b[0;36mraw_parse\u001b[0;34m(self, sentence, verbose)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_parse_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraw_parse_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jeremydohmann/.local/lib/python2.7/site-packages/nltk/parse/stanford.pyc\u001b[0m in \u001b[0;36mraw_parse_sents\u001b[0;34m(self, sentences, verbose)\u001b[0m\n\u001b[1;32m    178\u001b[0m         ]\n\u001b[1;32m    179\u001b[0m         return self._parse_trees_output(\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         )\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jeremydohmann/.local/lib/python2.7/site-packages/nltk/parse/stanford.pyc\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, cmd, input_, verbose)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 stdout, stderr = java(\n\u001b[0;32m--> 266\u001b[0;31m                     \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasspath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 )\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jeremydohmann/.local/lib/python2.7/site-packages/nltk/internals.pyc\u001b[0m in \u001b[0;36mjava\u001b[0;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decode_stdoutdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Java command failed : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Java command failed : [u'/usr/bin/java', u'-mx4g', '-cp', 'stanford-parser-full-2018-10-17/stanford-english-corenlp-2018-02-27-models.jar:stanford-parser-full-2018-10-17/stanford-english-corenlp-2018-02-27-models.jar:stanford-parser-full-2018-10-17/stanford-parser-3.9.2-sources.jar:stanford-parser-full-2018-10-17/stanford-parser-3.9.2-models.jar:stanford-parser-full-2018-10-17/slf4j-api-1.7.12-sources.jar:stanford-parser-full-2018-10-17/stanford-parser.jar:stanford-parser-full-2018-10-17/slf4j-api.jar:stanford-parser-full-2018-10-17/ejml-0.23.jar:stanford-parser-full-2018-10-17/stanford-parser-3.9.2-javadoc.jar', u'edu.stanford.nlp.parser.lexparser.LexicalizedParser', u'-model', u'edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz', u'-sentences', u'newline', u'-outputFormat', u'conll2007', u'-encoding', u'utf8', '/tmp/tmp2g1hsJ']"
     ]
    }
   ],
   "source": [
    "print_antagonists_and_agonists(f1, f2, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1.flush()\n",
    "f2.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
